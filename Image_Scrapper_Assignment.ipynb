{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6a45a63f-c3fc-46c2-b784-928bc6f2da3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "# Go to this given URL and solve the following questions\n",
    "# URL: https://www.youtube.com/@PW-Foundation/videos\n",
    "# Q1. Write a python program to extract the video URL of the first five videos.\n",
    "\n",
    "\n",
    "\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "url = \"https://www.youtube.com/@PW-Foundation/videos\"\n",
    "\n",
    "response = requests.get(url)\n",
    "soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "\n",
    "video_links = soup.select(\".style-scope ytd-grid-video-renderer a#thumbnail[href^='/watch']\")\n",
    "first_five_videos = video_links[:5]\n",
    "\n",
    "video_urls = []\n",
    "for video in first_five_videos:\n",
    "    video_url = \"https://www.youtube.com\" + video[\"href\"]\n",
    "    video_urls.append(video_url)\n",
    "\n",
    "print(video_urls)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44b721ae-40b8-431a-bf9f-2eddfea1bc3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q2. Write a python program to extract the URL of the video thumbnails of the first five video\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "url = \"https://www.youtube.com/@PW-Foundation/videos\"\n",
    "\n",
    "response = requests.get(url)\n",
    "soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "\n",
    "thumbnails = soup.select(\".style-scope ytd-grid-video-renderer .thumbnail span img\")\n",
    "first_five_thumbnails = thumbnails[:5]\n",
    "\n",
    "thumbnail_urls = []\n",
    "for thumbnail in first_five_thumbnails:\n",
    "    thumbnail_url = thumbnail[\"src\"]\n",
    "    thumbnail_urls.append(thumbnail_url)\n",
    "\n",
    "print(thumbnail_urls)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c9ed0ef-fbdd-40ea-a299-41aa56e3e3a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q3. Write a python program to extract the title of the first five videos.\n",
    "\n",
    "\n",
    "\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "url = \"https://www.youtube.com/@PW-Foundation/videos\"\n",
    "\n",
    "response = requests.get(url)\n",
    "soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "\n",
    "titles = soup.select(\".style-scope ytd-grid-video-renderer #video-title\")\n",
    "first_five_titles = titles[:5]\n",
    "\n",
    "video_titles = []\n",
    "for title in first_five_titles:\n",
    "    video_title = title.text.strip()\n",
    "    video_titles.append(video_title)\n",
    "\n",
    "print(video_titles)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f39e84c1-8d64-4bbf-9a1a-794545249f5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "# Q4. Python program to extract the number of views of the first five videos:\n",
    "\n",
    "\n",
    "\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "url = \"https://www.youtube.com/@PW-Foundation/videos\"\n",
    "\n",
    "response = requests.get(url)\n",
    "soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "\n",
    "views = soup.select(\".style-scope ytd-grid-video-renderer .ytd-thumbnail-overlay-side-panel-renderer span\")\n",
    "first_five_views = views[:5]\n",
    "\n",
    "video_views = []\n",
    "for view in first_five_views:\n",
    "    video_view = view.text.strip()\n",
    "    video_views.append(video_view)\n",
    "\n",
    "print(video_views)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f5f8bd54-2ddb-476f-a2c6-521e94f605ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "# Q5. Write a python program to extract the time of posting of video for the first five videos.\n",
    "\n",
    "\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "url = \"https://www.youtube.com/@PW-Foundation/videos\"\n",
    "\n",
    "response = requests.get(url)\n",
    "soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "\n",
    "times = soup.select(\".style-scope ytd-grid-video-renderer .ytd-thumbnail-overlay-time-status-renderer span\")\n",
    "first_five_times = times[:5]\n",
    "\n",
    "video_times = []\n",
    "for time in first_five_times:\n",
    "    video_time = time.text.strip()\n",
    "    video_times.append(video_time)\n",
    "\n",
    "print(video_times)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ba1a8a91-e6f4-49b1-a514-fe70ebbb6e38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data saved to scraped_data.csv successfully.\n"
     ]
    }
   ],
   "source": [
    "# Save all the data scraped in the above questions in a CSV file.\n",
    "\n",
    "\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import csv\n",
    "\n",
    "url = \"https://www.youtube.com/@PW-Foundation/videos\"\n",
    "\n",
    "response = requests.get(url)\n",
    "soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "\n",
    "# Extract the required information\n",
    "video_links = soup.select(\".style-scope ytd-grid-video-renderer a#thumbnail[href^='/watch']\")\n",
    "first_five_videos = video_links[:5]\n",
    "\n",
    "thumbnails = soup.select(\".style-scope ytd-grid-video-renderer .thumbnail span img\")\n",
    "first_five_thumbnails = thumbnails[:5]\n",
    "\n",
    "titles = soup.select(\".style-scope ytd-grid-video-renderer #video-title\")\n",
    "first_five_titles = titles[:5]\n",
    "\n",
    "views = soup.select(\".style-scope ytd-grid-video-renderer .ytd-thumbnail-overlay-side-panel-renderer span\")\n",
    "first_five_views = views[:5]\n",
    "\n",
    "times = soup.select(\".style-scope ytd-grid-video-renderer .ytd-thumbnail-overlay-time-status-renderer span\")\n",
    "first_five_times = times[:5]\n",
    "\n",
    "# Create a list of dictionaries containing the scraped data\n",
    "data = []\n",
    "for i in range(len(first_five_videos)):\n",
    "    video_url = \"https://www.youtube.com\" + first_five_videos[i][\"href\"]\n",
    "    thumbnail_url = first_five_thumbnails[i][\"src\"]\n",
    "    video_title = first_five_titles[i].text.strip()\n",
    "    video_view = first_five_views[i].text.strip()\n",
    "    video_time = first_five_times[i].text.strip()\n",
    "\n",
    "    data.append({\n",
    "        \"Video URL\": video_url,\n",
    "        \"Thumbnail URL\": thumbnail_url,\n",
    "        \"Title\": video_title,\n",
    "        \"Views\": video_view,\n",
    "        \"Time of Posting\": video_time\n",
    "    })\n",
    "\n",
    "# Save the data to a CSV file\n",
    "filename = \"scraped_data.csv\"\n",
    "fieldnames = [\"Video URL\", \"Thumbnail URL\", \"Title\", \"Views\", \"Time of Posting\"]\n",
    "\n",
    "with open(filename, \"w\", newline=\"\", encoding=\"utf-8\") as file:\n",
    "    writer = csv.DictWriter(file, fieldnames=fieldnames)\n",
    "    writer.writeheader()\n",
    "    writer.writerows(data)\n",
    "\n",
    "print(f\"Data saved to {filename} successfully.\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "eb5f9295-e8dc-410b-9640-e21ae66eb7d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting bs4\n",
      "  Downloading bs4-0.0.1.tar.gz (1.1 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: beautifulsoup4 in /opt/conda/lib/python3.10/site-packages (from bs4) (4.11.1)\n",
      "Requirement already satisfied: soupsieve>1.2 in /opt/conda/lib/python3.10/site-packages (from beautifulsoup4->bs4) (2.3.2.post1)\n",
      "Building wheels for collected packages: bs4\n",
      "  Building wheel for bs4 (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for bs4: filename=bs4-0.0.1-py3-none-any.whl size=1256 sha256=59dc14c443faf4bbae09362d5a109c1427f33573f7d154cfd76bded733bd7fce\n",
      "  Stored in directory: /home/jovyan/.cache/pip/wheels/e4/62/1d/d4d1bc4f33350ff84227f89b258edb552d604138e3739f5c83\n",
      "Successfully built bs4\n",
      "Installing collected packages: bs4\n",
      "Successfully installed bs4-0.0.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install bs4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3635736-c4dd-498d-b999-2f71673b2ba6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
